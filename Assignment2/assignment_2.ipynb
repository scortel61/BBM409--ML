{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b30bb5",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Part 1\n",
    "\n",
    "Group Member: Oğuzhan Taşçı\n",
    "\n",
    "Group Member: İbrahim Enes Genişyürek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "036a5737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/oguzhantasci/anaconda3/lib/python3.11/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/oguzhantasci/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f586a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6438f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gabor\n",
    "\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_dict = {}  # Dictionary to map folder names to numerical labels\n",
    "    label_counter = 0\n",
    "\n",
    "    for class_folder in os.listdir(folder):\n",
    "        class_path = os.path.join(folder, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            label_dict[class_folder] = label_counter\n",
    "            label_counter += 1\n",
    "\n",
    "            for filename in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, filename)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Change flags based on your needs\n",
    "                if img is not None:\n",
    "                    # resize image\n",
    "                    img = cv2.resize(img, (64, 64))  # Resize the image\n",
    "                    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "\n",
    "                    # Apply Gabor filters\n",
    "                    gabor_features = []\n",
    "                    for theta in [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]:\n",
    "                        for frequency in [0.1, 0.5, 1.0]:\n",
    "                            gabor_img, _ = gabor(gray_img, frequency, theta=theta)\n",
    "                            gabor_features.extend(gabor_img.flatten())\n",
    "\n",
    "                    # Extract histogram features using HSV color space\n",
    "                    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                    hist_features = []\n",
    "                    for channel in range(3):  # For each color channel (H, S, V)\n",
    "                        hist = cv2.calcHist([hsv_img], [channel], None, [256], [0, 256])\n",
    "                        hist_features.extend(hist.flatten())\n",
    "\n",
    "                    # Concatenate features\n",
    "                    all_features = np.concatenate([gabor_features, hist_features])\n",
    "                    \n",
    "                    # Append the features to the images list\n",
    "                    images.append(all_features)\n",
    "                    \n",
    "                    # Append the numerical label to the labels list\n",
    "                    labels.append(label_dict[class_folder])\n",
    "                    \n",
    "    # Convert lists to NumPy arrays and return them\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a836bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to folders\n",
    "train_folder = '/Users/oguzhantasci/Downloads/flowers/train'\n",
    "validation_folder = '/Users/oguzhantasci/Downloads/flowers/validation'\n",
    "test_folder = '/Users/oguzhantasci/Downloads/flowers/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6429f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, validation, and testing data\n",
    "X_train, y_train = load_images_and_labels(train_folder)\n",
    "X_validation, y_validation = load_images_and_labels(validation_folder)\n",
    "X_test, y_test = load_images_and_labels(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be38a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, target, depth, max_depth):\n",
    "        # Initialize a node with data, target labels, depth, and maximum depth\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature = None\n",
    "        self.threshold = None\n",
    "        self.prediction = self.most_common_class()\n",
    "# Calculate the most common class in the target labels of the node\n",
    "    def most_common_class(self):\n",
    "        unique_classes, counts = np.unique(self.target, return_counts=True)\n",
    "        index = np.argmax(counts) # Find the index of the most frequent class\n",
    "        return unique_classes[index] # Return the most common class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b33af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy function calculates the entropy of a set of labels\n",
    "def entropy(labels):\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / len(labels)\n",
    "    entropy_value = -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a3098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain function\n",
    "def information_gain(data, target, feature, threshold):\n",
    "    subset_left = target[data[:, feature] <= threshold]\n",
    "    subset_right = target[data[:, feature] > threshold]\n",
    "\n",
    "    total_entropy = entropy(target)\n",
    "    weighted_entropy = (len(subset_left) / len(target)) * entropy(subset_left) + \\\n",
    "                       (len(subset_right) / len(target)) * entropy(subset_right)\n",
    "\n",
    "    info_gain = total_entropy - weighted_entropy\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e06326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data, target):\n",
    "    num_features = data.shape[1]\n",
    "    best_info_gain = -1\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "\n",
    "    for feature in range(num_features):\n",
    "        unique_values = np.unique(data[:, feature])\n",
    "        for value in unique_values:\n",
    "            info_gain = information_gain(data, target, feature, value)\n",
    "            if info_gain > best_info_gain:\n",
    "                best_info_gain = info_gain\n",
    "                best_feature = feature\n",
    "                best_threshold = value\n",
    "\n",
    "    return best_feature, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c74b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data, target, depth, max_depth):\n",
    "    if len(np.unique(target)) == 1 or depth == max_depth:\n",
    "        return Node(data, target, depth, max_depth)\n",
    "\n",
    "    best_feature, best_threshold = find_best_split(data, target)\n",
    "\n",
    "    if best_feature is None:\n",
    "        return Node(data, target, depth, max_depth)\n",
    "\n",
    "    left_indices = data[:, best_feature] <= best_threshold\n",
    "    right_indices = data[:, best_feature] > best_threshold\n",
    "\n",
    "    left_data, left_target = data[left_indices], target[left_indices]\n",
    "    right_data, right_target = data[right_indices], target[right_indices]\n",
    "\n",
    "    node = Node(data, target, depth, max_depth)\n",
    "    node.feature = best_feature\n",
    "    node.threshold = best_threshold\n",
    "\n",
    "    node.left = build_tree(left_data, left_target, depth + 1, max_depth)\n",
    "    node.right = build_tree(right_data, right_target, depth + 1, max_depth)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c21eda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(node, sample):\n",
    "    if node.left is None and node.right is None:\n",
    "        return node.prediction\n",
    "\n",
    "    if sample[node.feature] <= node.threshold:\n",
    "        return predict_tree(node.left, sample)\n",
    "    else:\n",
    "        return predict_tree(node.right, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "588410c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c98619b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tree Depth 1, Accuracy: 0.1\n",
      "Tree Depth 1, Precision: 0.91\n",
      "Tree Depth 1, Recall: 0.1\n",
      "Tree Depth 1, F1 Score: 0.018181818181818184\n",
      "Tree Depth 1, Confusion Matrix:\n",
      "\n",
      "[[50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Tree Depth 2, Accuracy: 0.1\n",
      "Tree Depth 2, Precision: 0.91\n",
      "Tree Depth 2, Recall: 0.1\n",
      "Tree Depth 2, F1 Score: 0.018181818181818184\n",
      "Tree Depth 2, Confusion Matrix:\n",
      "\n",
      "[[50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Tree Depth 3, Accuracy: 0.1\n",
      "Tree Depth 3, Precision: 0.91\n",
      "Tree Depth 3, Recall: 0.1\n",
      "Tree Depth 3, F1 Score: 0.018181818181818184\n",
      "Tree Depth 3, Confusion Matrix:\n",
      "\n",
      "[[50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Tree Depth 4, Accuracy: 0.1\n",
      "Tree Depth 4, Precision: 0.91\n",
      "Tree Depth 4, Recall: 0.1\n",
      "Tree Depth 4, F1 Score: 0.018181818181818184\n",
      "Tree Depth 4, Confusion Matrix:\n",
      "\n",
      "[[50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Tree Depth 5, Accuracy: 0.1\n",
      "Tree Depth 5, Precision: 0.91\n",
      "Tree Depth 5, Recall: 0.1\n",
      "Tree Depth 5, F1 Score: 0.018181818181818184\n",
      "Tree Depth 5, Confusion Matrix:\n",
      "\n",
      "[[50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "max_depths = [1, 2, 3, 4, 5]\n",
    "for depth in max_depths:\n",
    "    root_node = build_tree(X_train, y_train, depth=depth, max_depth=depth)\n",
    "    y_pred = np.array([predict_tree(root_node, sample) for sample in X_test])\n",
    "\n",
    "    # Evaluate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nTree Depth {depth}, Accuracy: {accuracy}\")\n",
    "    \n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    print(f\"Tree Depth {depth}, Precision: {precision}\")\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Tree Depth {depth}, Recall: {recall}\")\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Tree Depth {depth}, F1 Score: {f1}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Tree Depth {depth}, Confusion Matrix:\\n\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0027d905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Rules:\n",
      "then class 0\n"
     ]
    }
   ],
   "source": [
    "def print_rules(node, rule=\"if \", depth=0):\n",
    "    if node.left is None and node.right is None:\n",
    "        print(f\"{'  ' * depth}then class {node.prediction}\")\n",
    "        return\n",
    "\n",
    "    print(f\"{'  ' * depth}{rule}Feature {node.feature} <= {node.threshold}\")\n",
    "    print_rules(node.left, \"and \", depth + 1)\n",
    "    print_rules(node.right, \"and not \", depth + 1)\n",
    "print(\"Decision Tree Rules:\")\n",
    "print_rules(root_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c8f74",
   "metadata": {},
   "source": [
    "## Error Analysis for Classification\n",
    "\n",
    "It seems that the performance metrics (Accuracy, Precision, Recall, F1 Score) and the confusion matrix are consistent across different tree depths. All the values are the same for each tree depth, which is unusual and might indicate an issue in my implementation or data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cc286",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this assignment, we learnt to generate Decision trees according to ID3 algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38561b",
   "metadata": {},
   "source": [
    "## References\n",
    "https://medium.com/geekculture/step-by-step-decision-tree-id3-algorithm-from-scratch-in-python-no-fancy-library-4822bbfdd88f\n",
    "\n",
    "https://iq.opengenus.org/id3-algorithm/\n",
    "\n",
    "https://stackoverflow.com\n",
    "\n",
    "BBM406 Lecture Notes\n",
    "\n",
    "https://towardsdatascience.com/id3-decision-tree-classifier-from-scratch-in-python-b38ef145fd90"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
